<img width="839" height="389" alt="image" src="https://github.com/user-attachments/assets/4c2e36d1-f34a-483c-ba19-00fa9adb86bb" />


# OrientAi
ðŸš€ PASO A PASO PARA SUBIR TODO EL PROYECTO ORIENTAI DESDE CERO
âœ… 1. Iniciar Minikube desde cero con mÃ¡s memoria

minikube stop
minikube delete
minikube start --memory=6144 --driver=docker

âœ… 2. Configurar Docker para trabajar dentro de Minikube

& minikube -p minikube docker-env | Invoke-Expression

âœ… 3. Instalar dependencias del backend

cd backend
npm install
npm install cors

âœ… 4. Verifica que server.js tenga cors habilitado
AsegÃºrate de que el archivo backend/server.js contenga:

const cors = require('cors');
app.use(cors());

âœ… 5. Volver a construir la imagen del backend
Estando en el directorio raÃ­z del proyecto (/OrientAI):

docker build -t orientai-backend ./backend

âœ… 6. Aplicar los archivos de Kubernetes (YAMLs)

kubectl apply -f mysql-secret.yaml
kubectl apply -f mysql-deployment.yaml
kubectl apply -f mysql-service.yaml

kubectl apply -f backend/backend-deployment.yaml
kubectl apply -f backend/backend-service.yaml

kubectl apply -f ollama-deployment.yaml
kubectl apply -f ollama-service.yaml

âœ… 7. Verifica que los pods estÃ©n ejecutÃ¡ndose

kubectl get pods
Todos deben estar en estado Running. Si alguno falla, revisa con:

kubectl logs deployment/backend
âœ… 8. Redirige el puerto del backend al host local
Esto te permitirÃ¡ comunicar el frontend con el backend:

kubectl port-forward service/backend-service 55683:3000

ðŸ§ª FRONTEND - MODO DESARROLLO
âœ… 9. Instalar dependencias del frontend

cd ../frontend
npm install

âœ… 10. Editar la URL en api.js

// frontend/src/api.js
export const enviarPregunta = (pregunta) => {
  return axios.post('http://127.0.0.1:55683/api/orientacion', { pregunta });
};

âœ… 11. Ejecutar el frontend

npm run dev
Abre el navegador en:

http://localhost:5173

âœ… 12. Verifica el flujo completo
Ingresa una pregunta como: "Â¿QuÃ© carrera me recomiendas si me gusta la biologÃ­a?"

El backend debe responder correctamente usando el modelo IA desde Ollama.


